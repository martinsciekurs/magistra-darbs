---
sidebar_position: 112
---

# BaseLLMCallback

**File:** `graphrag/callbacks/llm_callbacks.py`

## Overview

BaseLLMCallback is a base interface for callbacks that respond to token generation events in an LLM pipeline.

Purpose:
Define the contract for handling LLM events, specifically when new tokens are produced. Subclasses should override on_llm_new_token(token) to implement custom behavior.

Attributes:
- None defined at the base level. Concrete implementations may add state as needed.

Summary:
This class provides a lightweight, extendable hook for observing or processing tokens emitted by the language model.

Args:
- token: str The new token generated by the LLM. This value is passed to on_llm_new_token when a token is produced.

Returns:
- None

Raises:
- None

## Methods

### `on_llm_new_token`

```python
def on_llm_new_token(self, token: str)
```

