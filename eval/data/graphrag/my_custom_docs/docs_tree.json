{
  "repo": "graphrag",
  "structure": [
    {
      "name": "guide",
      "files": [
        {
          "path": "guide/index.md",
          "title": "graphrag Guide",
          "frontmatter": {
            "sidebar_position": 1
          },
          "content": "# graphrag Guide\n\nRun the documentation pipeline to generate the full guide."
        }
      ]
    },
    {
      "name": "modules",
      "files": [
        {
          "path": "modules/core-pipeline-orchestration.md",
          "title": "Core Pipeline Orchestration",
          "frontmatter": {
            "sidebar_position": 1
          },
          "content": "# Core Pipeline Orchestration\n\nMain indexing and query orchestration with workflow management, pipeline execution, and callback systems for coordinating the entire GraphRAG process\n\n## Overview\n\nCore Pipeline Orchestration module provides the main execution framework for GraphRAG indexing and query workflows, coordinating the entire process through workflow management, pipeline execution, and callback systems.\n\n### Architectural purpose\nProvides the main execution framework for GraphRAG indexing and query workflows, coordinating the entire process through workflow management, pipeline execution, and callback systems.\n\n### Key components and responsibilities\n- Pipeline class (graphrag/index/typing/pipeline.py): Manages and executes sequences of workflows in the graphrag indexing system\n- PipelineFactory class (graphrag/index/workflows/factory.py): Factory class for creating and managing indexing pipelines and workflows\n- WorkflowCallbacks protocol (graphrag/callbacks/workflow_callbacks.py): Protocol for handling workflow and pipeline lifecycle events\n- WorkflowCallbacksManager class (graphrag/callbacks/workflow_callbacks_manager.py): Manages workflow callbacks in a pipeline execution system\n- ConsoleWorkflowCallbacks class (graphrag/callbacks/console_workflow_callbacks.py): Console-based workflow callbacks for displaying progress and status information\n- NoopWorkflowCallbacks class (graphrag/callbacks/noop_workflow_callbacks.py): No-op implementation of workflow callbacks\n- QueryCallbacks class (graphrag/callbacks/query_callbacks.py): Callback handlers for query operations in GraphRAG\n- NoopQueryCallbacks class (graphrag/callbacks/noop_query_callbacks.py): No-operation implementation of the QueryCallbacks interface\n- BaseLLMCallback protocol (graphrag/callbacks/llm_callbacks.py): Protocol for monitoring language model token generation\n\n### Main entry points\n- run_pipeline function (graphrag/index/run/run_pipeline.py): Main execution function for running GraphRAG indexing pipelines\n- Pipeline class (graphrag/index/typing/pipeline.py): Primary class for managing workflow sequences\n- PipelineFactory class (graphrag/index/workflows/factory.py): Factory for creating pipelines based on configuration and indexing method\n\n### Args\nThis module does not accept arguments directly as it is a collection of classes and functions for pipeline orchestration.\n\n### Returns\nThis module does not return values directly as it provides classes and functions for building and executing pipelines.\n\n### Raises\n- Various exceptions may be raised by individual pipeline components during execution\n- Workflow execution errors may propagate through the pipeline system\n- Configuration errors may occur during pipeline creation via PipelineFactory\n\n### Example Usage\n```python\nfrom graphrag.index.run.run_pipeline import run_pipeline\nfrom graphrag.index.typing.pipeline import Pipeline\nfrom graphrag.index.workflows.factory import PipelineFactory\n\n# Create a pipeline using the factory\nfactory = PipelineFactory()\npipeline = factory.create_pipeline(config, indexing_method)\n\n# Run the pipeline\nresult = await run_pipeline(pipeline, context)\n\n## Files in this Module\n\n- [`graphrag/index/run/run_pipeline.py`](../files/graphrag-index-run-run-pipeline)\n- [`graphrag/index/typing/pipeline.py`](../files/graphrag-index-typing-pipeline)\n- [`graphrag/index/typing/workflow.py`](../files/graphrag-index-typing-workflow)\n- [`graphrag/index/workflows/factory.py`](../files/graphrag-index-workflows-factory)\n- [`graphrag/index/workflows/__init__.py`](../files/graphrag-index-workflows-init)\n- [`graphrag/callbacks/workflow_callbacks.py`](../files/graphrag-callbacks-workflow-callbacks)\n- [`graphrag/callbacks/workflow_callbacks_manager.py`](../files/graphrag-callbacks-workflow-callbacks-manager)\n- [`graphrag/callbacks/console_workflow_callbacks.py`](../files/graphrag-callbacks-console-workflow-callbacks)\n- [`graphrag/callbacks/noop_workflow_callbacks.py`](../files/graphrag-callbacks-noop-workflow-callbacks)\n- [`graphrag/callbacks/query_callbacks.py`](../files/graphrag-callbacks-query-callbacks)\n- [`graphrag/callbacks/noop_query_callbacks.py`](../files/graphrag-callbacks-noop-query-callbacks)\n- [`graphrag/callbacks/llm_callbacks.py`](../files/graphrag-callbacks-llm-callbacks)"
        },
        {
          "path": "modules/text-processing-embedding.md",
          "title": "Text Processing & Embedding",
          "frontmatter": {
            "sidebar_position": 2
          },
          "content": "# Text Processing & Embedding\n\nText chunking, splitting, and embedding operations for document processing and vector generation, including token management and embedding strategies\n\n## Overview\n\n### Architectural purpose\nProvides core text manipulation and vector generation capabilities for document processing pipelines in GraphRAG systems, handling text chunking, splitting, and embedding operations to prepare documents for vector storage and retrieval.\n\n### Key components and responsibilities\n- **chunk_text.py**: Main text chunking functionality for breaking text into smaller segments using various strategies, with the primary chunk_text function and strategy loading utilities\n- **strategies.py**: Text chunking strategies including sentence-based chunking using NLTK and token-based chunking using encoding models\n- **text_splitting.py**: Base classes and implementations for text splitting strategies including NoopTextSplitter, TextSplitter, and TokenTextSplitter using tiktoken\n- **check_token_limit.py**: Token limit checking functionality to determine whether text exceeds specified token limits for splitting decisions\n- **embed_text.py**: Main text embedding functionality supporting both in-memory embedding and vector store storage, with TextEmbedStrategyType enum for strategy selection\n- **openai.py**: OpenAI-based text embedding strategy implementation with asynchronous vector generation, text splitting, batching, and embedding execution\n- **mock.py**: Mock implementation for text embedding operations generating random embeddings for testing and development\n- **bootstrap.py**: NLTK resource bootstrapping functionality for downloading required data packages including punkt tokenizers and WordNet\n- **typing.py**: Type definitions for chunking and embedding operations\n\n### Main entry points\n- **chunk_text()**: Primary function for executing text chunking operations with various strategies\n- **run_sentences()**: Sentence-based chunking function using NLTK for natural language segmentation\n- **run_tokens()**: Token-based chunking function using encoding models for precise token control\n- **TextSplitter classes**: Abstract base and concrete implementations for text splitting strategies\n- **check_token_limit()**: Function for determining if text exceeds token limits requiring splitting\n- **embed_text()**: Main function for text embedding operations supporting multiple strategies\n- **TextEmbedStrategyType**: Enumeration for selecting embedding strategies (OpenAI, mock, etc.)\n- **bootstrap()**: Function for initializing NLTK resources required for text processing operations\n\n## Files in this Module\n\n- [`graphrag/index/operations/chunk_text/chunk_text.py`](../files/graphrag-index-operations-chunk-text-chunk-text)\n- [`graphrag/index/operations/chunk_text/strategies.py`](../files/graphrag-index-operations-chunk-text-strategies)\n- [`graphrag/index/text_splitting/text_splitting.py`](../files/graphrag-index-text-splitting-text-splitting)\n- [`graphrag/index/text_splitting/check_token_limit.py`](../files/graphrag-index-text-splitting-check-token-limit)\n- [`graphrag/index/operations/embed_text/embed_text.py`](../files/graphrag-index-operations-embed-text-embed-text)\n- [`graphrag/index/operations/embed_text/strategies/openai.py`](../files/graphrag-index-operations-embed-text-strategies-openai)\n- [`graphrag/index/operations/embed_text/strategies/mock.py`](../files/graphrag-index-operations-embed-text-strategies-mock)\n- [`graphrag/index/operations/chunk_text/bootstrap.py`](../files/graphrag-index-operations-chunk-text-bootstrap)\n- [`graphrag/index/operations/chunk_text/typing.py`](../files/graphrag-index-operations-chunk-text-typing)\n- [`graphrag/index/operations/embed_text/strategies/typing.py`](../files/graphrag-index-operations-embed-text-strategies-typing)"
        },
        {
          "path": "modules/knowledge-graph-extraction.md",
          "title": "Knowledge Graph Extraction",
          "frontmatter": {
            "sidebar_position": 3
          },
          "content": "# Knowledge Graph Extraction\n\nEntity, relationship, and claim extraction from text using LLMs and NLP techniques, including noun phrase extraction and graph intelligence strategies\n\n## Overview\n\nThe Knowledge Graph Extraction module provides comprehensive tools for extracting structured knowledge from unstructured text using LLMs and NLP techniques. It enables the construction of knowledge graphs through entity extraction, relationship identification, claim extraction, and noun phrase analysis with multiple extraction strategies including graph intelligence approaches.\n\n### Architectural purpose\nThis module serves as the core extraction engine for transforming unstructured text into structured knowledge graphs, supporting downstream graph-based reasoning and analysis through multiple complementary extraction techniques.\n\n### Key components and responsibilities\n- **Graph Extraction (extract_graph/)**: Implements entity and relationship extraction using language models with strategies including graph intelligence for iterative entity gleaning\n- **Covariate Extraction (extract_covariates/)**: Extracts structured claims and relationships between entities from text data using language models\n- **Noun Graph Construction (build_noun_graph/)**: Builds co-occurrence graphs from extracted noun phrases using syntactic parsing and regex-based extraction techniques\n- **Extractor Factories**: Provides configurable factories for creating different types of noun phrase extractors (syntactic, CFG, regex-based)\n- **Typing Definitions**: Standardizes extraction approaches and data structures across the module\n\n### Main entry points\n- **GraphExtractor**: Main class for processing text documents to extract entities and relationships using iterative gleaning\n- **ClaimExtractor**: Primary class for extracting structured claims and relationships between entities from text\n- **NounPhraseExtractorFactory**: Factory for creating different noun phrase extractor instances based on configuration\n- **SyntacticNounPhraseExtractor**: Syntactic parsing-based noun phrase extractor using SpaCy's dependency parsing and NER\n- **RegexENNounPhraseExtractor**: Regex-based noun phrase extractor for English text using TextBlob's POS tagging\n- **extract_graph()**: Main function for graph extraction operations from text data using entity extraction strategies\n- **extract_covariates()**: Primary function for extracting covariates (structured claims) from text data in DataFrames\n- **build_noun_graph()**: Main function for noun graph construction from text units by extracting noun phrases and building co-occurrence relationships\n\n## Files in this Module\n\n- [`graphrag/index/operations/extract_graph/extract_graph.py`](../files/graphrag-index-operations-extract-graph-extract-graph)\n- [`graphrag/index/operations/extract_graph/graph_extractor.py`](../files/graphrag-index-operations-extract-graph-graph-extractor)\n- [`graphrag/index/operations/extract_graph/graph_intelligence_strategy.py`](../files/graphrag-index-operations-extract-graph-graph-intelligence-strategy)\n- [`graphrag/index/operations/extract_covariates/extract_covariates.py`](../files/graphrag-index-operations-extract-covariates-extract-covariates)\n- [`graphrag/index/operations/extract_covariates/claim_extractor.py`](../files/graphrag-index-operations-extract-covariates-claim-extractor)\n- [`graphrag/index/operations/build_noun_graph/build_noun_graph.py`](../files/graphrag-index-operations-build-noun-graph-build-noun-graph)\n- [`graphrag/index/operations/build_noun_graph/np_extractors/factory.py`](../files/graphrag-index-operations-build-noun-graph-np-extractors-factory)\n- [`graphrag/index/operations/build_noun_graph/np_extractors/syntactic_parsing_extractor.py`](../files/graphrag-index-operations-build-noun-graph-np-extractors-syntactic-parsing-extractor)\n- [`graphrag/index/operations/build_noun_graph/np_extractors/regex_extractor.py`](../files/graphrag-index-operations-build-noun-graph-np-extractors-regex-extractor)\n- [`graphrag/index/operations/extract_graph/typing.py`](../files/graphrag-index-operations-extract-graph-typing)\n- [`graphrag/index/operations/extract_covariates/typing.py`](../files/graphrag-index-operations-extract-covariates-typing)"
        },
        {
          "path": "modules/graph-operations-structure-analysis.md",
          "title": "Graph Operations & Structure Analysis",
          "frontmatter": {
            "sidebar_position": 4
          },
          "content": "# Graph Operations & Structure Analysis\n\nCore graph operations including pruning, degree computation, graph creation, and structural analysis for knowledge graph processing\n\n## Overview\n\nCore graph operations and utilities for knowledge graph processing, including pruning, degree computation, graph creation, structural analysis, and entity/relationship finalization. Provides essential functions for filtering, analyzing, transforming, and finalizing graph data structures in knowledge graph workflows.\n\n### Architectural purpose\nThis module provides the core graph manipulation and analysis operations for knowledge graph processing pipelines, enabling graph creation, filtering, metric computation, and structural transformations.\n\n### Key components and responsibilities\n- prune_graph.py: Graph pruning operations for filtering and cleaning network graphs based on frequency, degree thresholds, and edge weight percentiles\n- compute_degree.py: Node degree computation for NetworkX graphs, producing structured pandas DataFrame outputs\n- compute_edge_combined_degree.py: Combined degree metrics for edges with standardized column naming and degree information joining\n- create_graph.py: NetworkX graph creation from pandas DataFrames for edges and optional nodes with configurable attributes\n- graph_to_dataframes.py: Conversion of NetworkX graphs to pandas DataFrames for easier data manipulation and analysis\n- graphs.py: Graph analysis utilities for community detection (modularity using hierarchical Leiden clustering) and edge weight calculations (PMI, RRF)\n- stable_lcc.py: Utilities for extracting largest connected components in a stable, deterministic way with consistent ordering\n- finalize_entities.py: Entity graph creation, embedding, and layout operations for transforming entity data into complete graph representations\n- finalize_relationships.py: Relationship data finalization including duplicate removal, combined degree computation, and unique identifier generation\n\n### Main entry points\n- prune_graph: Remove nodes based on frequency and degree thresholds and edges based on weight percentile\n- compute_degree: Calculate degree of each node in a NetworkX graph\n- compute_edge_combined_degree: Compute combined degree metrics for edges in graph data structures\n- create_graph: Convert node and edge dataframes into NetworkX graph structures\n- graph_to_dataframes: Deconstruct NetworkX graphs into separate nodes and edges DataFrames\n- calculate_root_modularity, calculate_leaf_modularity, calculate_weighted_modularity, calculate_lcc_modularity: Modularity calculation variants using hierarchical Leiden clustering\n- calculate_pmi_edge_weights, calculate_rrf_edge_weights: Edge weight computation methods\n- stable_largest_connected_component: Extract largest connected component with stable, deterministic ordering\n- finalize_entities: Orchestrate entity graph creation, embedding, and layout operations\n- finalize_relationships: Transform relationship data by removing duplicates, computing combined degree metrics, and generating unique identifiers\n\n## Files in this Module\n\n- [`graphrag/index/operations/prune_graph.py`](../files/graphrag-index-operations-prune-graph)\n- [`graphrag/index/operations/compute_degree.py`](../files/graphrag-index-operations-compute-degree)\n- [`graphrag/index/operations/compute_edge_combined_degree.py`](../files/graphrag-index-operations-compute-edge-combined-degree)\n- [`graphrag/index/operations/create_graph.py`](../files/graphrag-index-operations-create-graph)\n- [`graphrag/index/operations/graph_to_dataframes.py`](../files/graphrag-index-operations-graph-to-dataframes)\n- [`graphrag/index/utils/graphs.py`](../files/graphrag-index-utils-graphs)\n- [`graphrag/index/utils/stable_lcc.py`](../files/graphrag-index-utils-stable-lcc)\n- [`graphrag/index/operations/finalize_entities.py`](../files/graphrag-index-operations-finalize-entities)\n- [`graphrag/index/operations/finalize_relationships.py`](../files/graphrag-index-operations-finalize-relationships)"
        },
        {
          "path": "modules/community-detection-summarization.md",
          "title": "Community Detection & Summarization",
          "frontmatter": {
            "sidebar_position": 5
          },
          "content": "# Community Detection & Summarization\n\nCommunity detection using Leiden algorithm, hierarchical organization, and summary generation for graph communities and descriptions\n\n## Overview\n\n### Architectural purpose\nThis module provides hierarchical community detection and summarization capabilities for graph data, enabling automated analysis of graph structures through clustering algorithms and natural language generation of community insights.\n\n### Key components and responsibilities\n- **cluster_graph.py**: Applies hierarchical clustering to graphs using the Leiden algorithm, computing community hierarchies and mappings\n- **summarize_communities/summarize_communities.py**: Generates community summaries and reports from graph data using language models\n- **summarize_communities/community_reports_extractor.py**: Extracts structured community reports including titles, summaries, findings, and ratings\n- **summarize_descriptions/summarize_descriptions.py**: Summarizes entity and relationship descriptions in graphs using language models\n- **finalize_community_reports.py**: Merges community reports with community metadata for final report generation\n- **summarize_communities/build_mixed_context.py**: Constructs parent community contexts by combining sub-community contexts and reports within token limits\n- **summarize_communities/explode_communities.py**: Transforms community and entity data into individual node representations for filtering operations\n- **summarize_communities/graph_context/context_builder.py**: Builds graph context for community summarization, managing hierarchical community context across levels\n- **summarize_communities/text_unit_context/context_builder.py**: Prepares text unit-based context data and manages context across community hierarchy levels\n- **summarize_communities/utils.py**: Provides helper functions for community summarization operations including level extraction\n\n### Main entry points\n- **cluster_graph()**: Main function for applying hierarchical clustering to graphs\n- **summarize_communities()**: Primary function for generating community summaries and reports\n- **summarize_descriptions()**: Main function for summarizing entity and relationship descriptions\n- **finalize_community_reports()**: Function for merging community reports with metadata\n- **CommunityReportsExtractor**: Class for extracting structured community reports from input text\n- **build_mixed_context()**: Function for constructing parent community contexts from sub-community data\n- **explode_communities()**: Function for transforming community data into node representations\n\n## Files in this Module\n\n- [`graphrag/index/operations/cluster_graph.py`](../files/graphrag-index-operations-cluster-graph)\n- [`graphrag/index/operations/summarize_communities/summarize_communities.py`](../files/graphrag-index-operations-summarize-communities-summarize-communities)\n- [`graphrag/index/operations/summarize_communities/community_reports_extractor.py`](../files/graphrag-index-operations-summarize-communities-community-reports-extractor)\n- [`graphrag/index/operations/summarize_descriptions/summarize_descriptions.py`](../files/graphrag-index-operations-summarize-descriptions-summarize-descriptions)\n- [`graphrag/index/operations/finalize_community_reports.py`](../files/graphrag-index-operations-finalize-community-reports)\n- [`graphrag/index/operations/summarize_communities/build_mixed_context.py`](../files/graphrag-index-operations-summarize-communities-build-mixed-context)\n- [`graphrag/index/operations/summarize_communities/explode_communities.py`](../files/graphrag-index-operations-summarize-communities-explode-communities)\n- [`graphrag/index/operations/summarize_communities/graph_context/context_builder.py`](../files/graphrag-index-operations-summarize-communities-graph-context-context-builder)\n- [`graphrag/index/operations/summarize_communities/text_unit_context/context_builder.py`](../files/graphrag-index-operations-summarize-communities-text-unit-context-context-builder)\n- [`graphrag/index/operations/summarize_communities/utils.py`](../files/graphrag-index-operations-summarize-communities-utils)"
        },
        {
          "path": "modules/graph-embedding-visualization.md",
          "title": "Graph Embedding & Visualization",
          "frontmatter": {
            "sidebar_position": 6
          },
          "content": "# Graph Embedding & Visualization\n\nGraph embedding algorithms (node2vec), layout operations (UMAP), graph visualization preparation, and snapshot generation\n\n## Overview\n\nThis module provides graph embedding and visualization capabilities for network analysis. It implements algorithms for converting graph structures into vector representations and preparing them for visualization.\n\n### Architectural purpose\nThe module enables graph analysis by transforming network structures into numerical embeddings and 2D layouts for visualization, supporting downstream tasks like clustering, similarity search, and interactive exploration.\n\n### Key components and responsibilities\n- **embed_graph.py**: Main interface for graph embedding using node2vec algorithm\n- **embed_node2vec.py**: Node2Vec implementation for generating node embeddings via random walks\n- **layout_graph.py**: Graph layout functionality for positioning nodes in 2D space\n- **umap.py**: UMAP-based layout for projecting high-dimensional embeddings to 2D coordinates\n- **zero.py**: Fallback layout implementation with zero positions\n- **snapshot_graphml.py**: Graph snapshot generation and persistence in GraphML format\n- **embed_graph/typing.py**: Type definitions for graph embedding operations\n- **layout_graph/typing.py**: Type definitions including NodePosition dataclass for layout results\n\n### Main entry points\n- embed_graph: Main function for embedding graphs using node2vec\n- embed_node2vec: Node2Vec implementation for node embeddings\n- layout_graph: Primary function for computing graph layouts\n- snapshot_graphml: Function for saving graph snapshots in GraphML format\n- NodePosition: Dataclass representing node positions in visualizations\n\n### Dependencies\n- networkx: Graph manipulation and representation\n- graspologic: Node2Vec implementation for graph embeddings\n- umap-learn: UMAP algorithm for dimensionality reduction\n- pandas: Data structure for layout results\n\n### Typical use cases\n1. Generating node embeddings for similarity search and clustering\n2. Creating 2D visualizations of graph structures for exploration\n3. Saving graph snapshots for persistence and analysis\n4. Preparing graph data for downstream machine learning tasks\n\n### Examples\nBasic usage pattern:\n1. Embed a graph using node2vec: `embeddings = embed_graph(graph, config)`\n2. Compute 2D layout: `positions = layout_graph(graph, embeddings)`\n3. Save snapshot: `snapshot_graphml(graph, storage)`\n\nThe module supports configurable parameters for embedding dimensions, random walk lengths, and layout optimization settings.\n\n## Files in this Module\n\n- [`graphrag/index/operations/embed_graph/embed_graph.py`](../files/graphrag-index-operations-embed-graph-embed-graph)\n- [`graphrag/index/operations/embed_graph/embed_node2vec.py`](../files/graphrag-index-operations-embed-graph-embed-node2vec)\n- [`graphrag/index/operations/layout_graph/layout_graph.py`](../files/graphrag-index-operations-layout-graph-layout-graph)\n- [`graphrag/index/operations/layout_graph/umap.py`](../files/graphrag-index-operations-layout-graph-umap)\n- [`graphrag/index/operations/layout_graph/zero.py`](../files/graphrag-index-operations-layout-graph-zero)\n- [`graphrag/index/operations/snapshot_graphml.py`](../files/graphrag-index-operations-snapshot-graphml)\n- [`graphrag/index/operations/embed_graph/typing.py`](../files/graphrag-index-operations-embed-graph-typing)\n- [`graphrag/index/operations/layout_graph/typing.py`](../files/graphrag-index-operations-layout-graph-typing)"
        },
        {
          "path": "modules/query-engine-search-methods.md",
          "title": "Query Engine & Search Methods",
          "frontmatter": {
            "sidebar_position": 7
          },
          "content": "# Query Engine & Search Methods\n\nMultiple search strategies (Global, Local, DRIFT, Basic) with context building, dynamic community selection, and LLM integration\n\n## Overview\n\nThis module provides a comprehensive query engine system with multiple search strategies for GraphRAG query processing. It implements four distinct search methods (Global, Local, DRIFT, Basic) with specialized context building, dynamic community selection, and LLM integration capabilities.\n\nArgs:\n    query: User query string to be processed by the search engine.\n    search_type: Type of search strategy to use - \"global\", \"local\", \"drift\", or \"basic\".\n    config: Configuration object containing model settings, context parameters, and search options.\n    knowledge_graph: Knowledge graph data structure containing entities, relationships, and communities.\n\nReturns:\n    SearchResult object containing:\n        - answer: Generated response to the query\n        - sources: List of source documents or context used\n        - confidence: Confidence score for the answer\n        - metadata: Additional search metadata and processing details\n\nRaises:\n    ValueError: If invalid search_type is provided or required configuration is missing.\n    ConnectionError: If LLM service connection fails during search execution.\n    TimeoutError: If search operation exceeds configured timeout limits.\n\nExamples:\n    Basic usage:\n        from graphrag.query.factory import get_global_search_engine\n        \n        search_engine = get_global_search_engine(config)\n        result = search_engine.search(query=\"What are the main themes?\", knowledge_graph=kg_data)\n        print(result.answer)\n\n    Using DRIFT search (Dynamic Retrieval of Information with Follow-up Tasks):\n        from graphrag.query.factory import get_drift_search_engine\n        \n        drift_engine = get_drift_search_engine(config)\n        result = drift_engine.search(query=\"Explain the relationship between concepts A and B\", knowledge_graph=kg_data)\n\nNote:\n    DRIFT stands for Dynamic Retrieval of Information with Follow-up Tasks, which coordinates local search operations and processes primer results through a multi-step refinement process.\n\n## Files in this Module\n\n- [`graphrag/query/factory.py`](../files/graphrag-query-factory)\n- [`graphrag/query/structured_search/global_search/search.py`](../files/graphrag-query-structured-search-global-search-search)\n- [`graphrag/query/structured_search/local_search/search.py`](../files/graphrag-query-structured-search-local-search-search)\n- [`graphrag/query/structured_search/drift_search/search.py`](../files/graphrag-query-structured-search-drift-search-search)\n- [`graphrag/query/structured_search/basic_search/search.py`](../files/graphrag-query-structured-search-basic-search-search)\n- [`graphrag/query/context_builder/builders.py`](../files/graphrag-query-context-builder-builders)\n- [`graphrag/query/context_builder/dynamic_community_selection.py`](../files/graphrag-query-context-builder-dynamic-community-selection)\n- [`graphrag/query/context_builder/entity_extraction.py`](../files/graphrag-query-context-builder-entity-extraction)\n- [`graphrag/query/question_gen/base.py`](../files/graphrag-query-question-gen-base)\n- [`graphrag/query/question_gen/local_gen.py`](../files/graphrag-query-question-gen-local-gen)\n- [`graphrag/query/context_builder/community_context.py`](../files/graphrag-query-context-builder-community-context)\n- [`graphrag/query/context_builder/local_context.py`](../files/graphrag-query-context-builder-local-context)\n- [`graphrag/query/context_builder/source_context.py`](../files/graphrag-query-context-builder-source-context)"
        },
        {
          "path": "modules/llm-integration-prompt-management.md",
          "title": "LLM Integration & Prompt Management",
          "frontmatter": {
            "sidebar_position": 8
          },
          "content": "# LLM Integration & Prompt Management\n\nLanguage model abstraction, prompt generation, prompt tuning, and system prompt management across indexing and query operations\n\n## Overview\n\n### Architectural purpose\nProvides a unified language model abstraction layer and comprehensive prompt management system for the GraphRAG framework. Enables dynamic model creation, registration, and management while maintaining consistent protocols for chat and embedding operations across both indexing and query workflows.\n\n### Key components and responsibilities\n**Language Model Management:**\n- ModelFactory: Factory pattern implementation for creating and managing ChatModel and EmbeddingModel instances with dynamic registration capabilities\n- ModelManager: Singleton class for centralized registration and management of chat and embedding language models by unique names\n- Base Protocols: EmbeddingModel protocol for generating vector representations and ChatModel protocol for conversational interactions\n\n**Prompt Tuning Components:**\n- Prompt tuning generator and loader modules for optimizing prompt performance\n- Input loader functionality for loading and sampling document chunks with configurable chunking parameters\n\n**System Prompt Management:**\n- Indexing prompts: extract_graph, extract_claims, summarize_descriptions, and community_report for graph construction and analysis\n- Query prompts: global_search_map_system_prompt, global_search_reduce_system_prompt, local_search_system_prompt, drift_search_system_prompt, basic_search_system_prompt, and question_gen_system_prompt for various search and question generation operations\n\n### Main entry points\n- ModelFactory: Central registry for ChatModel and EmbeddingModel implementations with create_chat_model and create_embedding_model methods\n- ModelManager: Singleton instance for model registration and retrieval via register_chat, register_embedding, get_embedding_model methods\n- EmbeddingModel and ChatModel protocols: Standardized interfaces for embedding generation and conversational interactions\n- Prompt loading utilities: load_docs_in_chunks function for document chunk preparation in prompt tuning workflows\n\n## Files in this Module\n\n- [`graphrag/language_model/factory.py`](../files/graphrag-language-model-factory)\n- [`graphrag/language_model/manager.py`](../files/graphrag-language-model-manager)\n- [`graphrag/language_model/protocol/base.py`](../files/graphrag-language-model-protocol-base)\n- [`graphrag/prompt_tune/generator/__init__.py`](../files/graphrag-prompt-tune-generator-init)\n- [`graphrag/prompt_tune/loader/input.py`](../files/graphrag-prompt-tune-loader-input)\n- [`graphrag/prompts/index/extract_graph.py`](../files/graphrag-prompts-index-extract-graph)\n- [`graphrag/prompts/query/global_search_map_system_prompt.py`](../files/graphrag-prompts-query-global-search-map-system-prompt)\n- [`graphrag/prompts/query/global_search_reduce_system_prompt.py`](../files/graphrag-prompts-query-global-search-reduce-system-prompt)\n- [`graphrag/prompts/query/local_search_system_prompt.py`](../files/graphrag-prompts-query-local-search-system-prompt)\n- [`graphrag/prompts/query/drift_search_system_prompt.py`](../files/graphrag-prompts-query-drift-search-system-prompt)\n- [`graphrag/prompts/index/community_report.py`](../files/graphrag-prompts-index-community-report)\n- [`graphrag/prompts/index/extract_claims.py`](../files/graphrag-prompts-index-extract-claims)\n- [`graphrag/prompts/index/summarize_descriptions.py`](../files/graphrag-prompts-index-summarize-descriptions)\n- [`graphrag/prompts/query/basic_search_system_prompt.py`](../files/graphrag-prompts-query-basic-search-system-prompt)\n- [`graphrag/prompts/query/question_gen_system_prompt.py`](../files/graphrag-prompts-query-question-gen-system-prompt)"
        },
        {
          "path": "modules/storage-vector-infrastructure.md",
          "title": "Storage & Vector Infrastructure",
          "frontmatter": {
            "sidebar_position": 9
          },
          "content": "# Storage & Vector Infrastructure\n\nMulti-backend storage (file, blob, cosmosdb) and vector store implementations for data persistence and retrieval\n\n## Overview\n\n### Architectural purpose\nProvides multi-backend storage solutions for pipeline data persistence and vector store implementations for embedding storage and retrieval. Enables flexible data storage across file systems, Azure Blob Storage, CosmosDB, and in-memory options, along with vector similarity search capabilities.\n\n### Key components and responsibilities\n**Storage Factory (graphrag/storage/factory.py)**: Factory class for creating and managing pipeline storage implementations with registration and instantiation of blob, CosmosDB, file, and memory storage types.\n\n**Pipeline Storage Base (graphrag/storage/pipeline_storage.py)**: Abstract base class defining interface for key-value storage with metadata capabilities, file pattern matching, and hierarchical organization through child storage instances.\n\n**File Pipeline Storage (graphrag/storage/file_pipeline_storage.py)**: File system-based storage implementation supporting asynchronous operations, filtering, and metadata extraction for pipeline data.\n\n**Blob Pipeline Storage (graphrag/storage/blob_pipeline_storage.py)**: Azure Blob Storage integration handling authentication, container management, and blob operations for storing and retrieving pipeline data including pandas DataFrames in JSON and Parquet formats.\n\n**CosmosDB Pipeline Storage (graphrag/storage/cosmosdb_pipeline_storage.py)**: CosmosDB-based storage solution for pipeline data supporting Parquet files, JSON data, and other file formats with database management capabilities.\n\n**Vector Store Factory (graphrag/vector_stores/factory.py)**: Factory pattern implementation for creating vector store instances based on type identifiers, managing registration and instantiation of Azure AI Search, CosmosDB, and LanceDB vector stores.\n\n**Vector Store Base (graphrag/vector_stores/base.py)**: Abstract base class defining interface for vector storage operations including document loading, similarity search, and document retrieval with default vector store implementations.\n\n**Azure AI Search Vector Store (graphrag/vector_stores/azure_ai_search.py)**: Azure AI Search implementation for storing and retrieving vector embeddings with document storage, similarity search by vector or text, and service integration.\n\n**LanceDB Vector Store (graphrag/vector_stores/lancedb.py)**: LanceDB implementation providing vector storage and similarity search capabilities using LanceDB as the backend for document storage, retrieval, and similarity search operations.\n\n**CosmosDB Vector Store (graphrag/vector_stores/cosmosdb.py)**: CosmosDB vector store for storing and searching vector embeddings using Azure Cosmos DB with connection management, document loading with embeddings, and similarity searches using text and vector queries.\n\n### Main entry points\nStorageFactory: Factory class for creating and managing pipeline storage implementations with registration capabilities.\nPipelineStorage: Abstract base class for pipeline data storage operations with key-value storage and metadata capabilities.\nFilePipelineStorage: File-based pipeline storage system implementation.\nBlobPipelineStorage: Azure Blob Storage integration for pipeline data storage.\nCosmosDBPipelineStorage: CosmosDB-based storage solution for pipeline data.\nVectorStoreFactory: Factory class for creating vector store instances with type-based registration.\nBaseVectorStore: Abstract base class for vector store implementations with document loading and similarity search operations.\nAzureAISearchVectorStore: Azure AI Search vector store implementation.\nLanceDBVectorStore: LanceDB vector store implementation.\nCosmosDBVectorStore: CosmosDB vector store implementation.\n\n## Files in this Module\n\n- [`graphrag/storage/factory.py`](../files/graphrag-storage-factory)\n- [`graphrag/storage/pipeline_storage.py`](../files/graphrag-storage-pipeline-storage)\n- [`graphrag/storage/file_pipeline_storage.py`](../files/graphrag-storage-file-pipeline-storage)\n- [`graphrag/storage/blob_pipeline_storage.py`](../files/graphrag-storage-blob-pipeline-storage)\n- [`graphrag/storage/cosmosdb_pipeline_storage.py`](../files/graphrag-storage-cosmosdb-pipeline-storage)\n- [`graphrag/vector_stores/factory.py`](../files/graphrag-vector-stores-factory)\n- [`graphrag/vector_stores/base.py`](../files/graphrag-vector-stores-base)\n- [`graphrag/vector_stores/azure_ai_search.py`](../files/graphrag-vector-stores-azure-ai-search)\n- [`graphrag/vector_stores/lancedb.py`](../files/graphrag-vector-stores-lancedb)\n- [`graphrag/vector_stores/cosmosdb.py`](../files/graphrag-vector-stores-cosmosdb)"
        },
        {
          "path": "modules/configuration-data-models.md",
          "title": "Configuration & Data Models",
          "frontmatter": {
            "sidebar_position": 10
          },
          "content": "# Configuration & Data Models\n\nConfiguration management, data schema definitions, environment handling, and model validation for the entire system\n\n## Overview\n\nThis module provides configuration management, data schema definitions, environment handling, and model validation for the entire GraphRAG system.\n\n### Architectural purpose\nThe Configuration & Data Models module serves as the foundation for GraphRAG's configuration system and data modeling layer, providing structured configuration management and standardized data schemas that ensure consistency across the entire application.\n\n### Key components and responsibilities\n- **Configuration Loading**: `load_config.py` provides the main `load_config` function for loading configuration from YAML/JSON files with environment variable substitution and CLI overrides\n- **Configuration Models**: `graph_rag_config.py` defines the central `GraphRagConfig` class using Pydantic for configuration validation and management\n- **Configuration Creation**: `create_graphrag_config.py` offers the `create_graphrag_config` function for programmatic configuration creation\n- **Environment Handling**: `environment_reader.py` provides the `EnvironmentReader` class for type-safe environment variable reading with section-based organization\n- **Data Models**: Core data schemas including `Entity`, `Relationship`, `Community`, `TextUnit`, `Document`, and `CommunityReport` classes for representing graph elements and content\n- **Environment File Support**: `read_dotenv.py` provides `read_dotenv` function for loading environment variables from .env files\n\n### Main entry points\n- `load_config()`: Primary function for loading configuration from files with environment variable support\n- `create_graphrag_config()`: Function for programmatically creating GraphRAG configurations\n- `GraphRagConfig`: Main configuration container class managing all system settings\n- `EnvironmentReader`: Class for reading configuration values from environment variables\n- Core data model classes: `Entity`, `Relationship`, `Community`, `TextUnit`, `Document`, `CommunityReport`\n\n### Usage examples\n```python\n# Load configuration from file\nfrom graphrag.config import load_config\nconfig = load_config(\"config.yaml\")\n\n# Create configuration programmatically\nfrom graphrag.config import create_graphrag_config\nconfig = create_graphrag_config(&#123;\"llm\": &#123;\"model\": \"gpt-4\"&#125;&#125;)\n\n# Use environment reader\nfrom graphrag.config import EnvironmentReader\nenv = EnvironmentReader()\napi_key = env.read_key(\"OPENAI_API_KEY\")\n\n# Work with data models\nfrom graphrag.data_model import Entity, Relationship\nentity = Entity(id=\"e1\", name=\"Example Entity\")\nrelationship = Relationship(source=\"e1\", target=\"e2\", description=\"connected to\")\n```\n\n### Related components\n- Configuration files are typically YAML or JSON format with support for environment variable interpolation\n- Data models use Python dataclasses for structured data handling with serialization support\n- The module integrates with Pydantic for runtime type checking and validation\n- Environment variables follow the pattern of being prefixed for namespacing\n\n## Files in this Module\n\n- [`graphrag/config/load_config.py`](../files/graphrag-config-load-config)\n- [`graphrag/config/create_graphrag_config.py`](../files/graphrag-config-create-graphrag-config)\n- [`graphrag/config/models/graph_rag_config.py`](../files/graphrag-config-models-graph-rag-config)\n- [`graphrag/config/environment_reader.py`](../files/graphrag-config-environment-reader)\n- [`graphrag/data_model/schemas.py`](../files/graphrag-data-model-schemas)\n- [`graphrag/data_model/entity.py`](../files/graphrag-data-model-entity)\n- [`graphrag/data_model/relationship.py`](../files/graphrag-data-model-relationship)\n- [`graphrag/data_model/community.py`](../files/graphrag-data-model-community)\n- [`graphrag/data_model/text_unit.py`](../files/graphrag-data-model-text-unit)\n- [`graphrag/data_model/document.py`](../files/graphrag-data-model-document)\n- [`graphrag/data_model/community_report.py`](../files/graphrag-data-model-community-report)\n- [`graphrag/config/models/__init__.py`](../files/graphrag-config-models-init)\n- [`graphrag/config/read_dotenv.py`](../files/graphrag-config-read-dotenv)\n- [`graphrag/config/defaults.py`](../files/graphrag-config-defaults)"
        },
        {
          "path": "modules/cli-api-interfaces.md",
          "title": "CLI & API Interfaces",
          "frontmatter": {
            "sidebar_position": 11
          },
          "content": "# CLI & API Interfaces\n\nCommand-line interface and programmatic API for library consumption, user interaction, and system initialization\n\n## Overview\n\nThe CLI & API Interfaces module provides both command-line and programmatic interfaces for interacting with the GraphRAG system. It enables users to perform knowledge graph operations through terminal commands or direct Python API calls, supporting project setup, indexing, querying, and prompt tuning workflows.\n\n## Files in this Module\n\n- [`graphrag/cli/main.py`](../files/graphrag-cli-main)\n- [`graphrag/cli/index.py`](../files/graphrag-cli-index)\n- [`graphrag/cli/query.py`](../files/graphrag-cli-query)\n- [`graphrag/cli/initialize.py`](../files/graphrag-cli-initialize)\n- [`graphrag/api/index.py`](../files/graphrag-api-index)\n- [`graphrag/api/query.py`](../files/graphrag-api-query)\n- [`graphrag/api/prompt_tune.py`](../files/graphrag-api-prompt-tune)\n- [`graphrag/__main__.py`](../files/graphrag-main)\n- [`graphrag/utils/cli.py`](../files/graphrag-utils-cli)\n- [`graphrag/utils/api.py`](../files/graphrag-utils-api)"
        },
        {
          "path": "modules/unified-search-application.md",
          "title": "Unified Search Application",
          "frontmatter": {
            "sidebar_position": 12
          },
          "content": "# Unified Search Application\n\nStreamlit-based demo application for comparing search methods, visualizing results, and interactive exploration of GraphRAG outputs\n\n## Overview\n\nStreamlit-based demo application for comparing search methods, visualizing results, and interactive exploration of GraphRAG outputs.\n\n### Architectural purpose\nThis module serves as a unified search application that demonstrates and compares different search methodologies while providing interactive visualization of GraphRAG knowledge graph outputs.\n\n### Key components and responsibilities\n- **app_logic.py**: Core application logic for initializing the app, loading datasets and knowledge models, and executing various search operations\n- **home_page.py**: Main entry point module for the GraphRAG application's Streamlit interface with UI management and event handlers\n- **knowledge_loader/data_prep.py**: Data loading functions for accessing indexed knowledge data from various sources\n- **knowledge_loader/data_sources/loader.py**: Main entry point for loading knowledge datasets and their configurations from local or blob storage\n- **ui/search.py**: UI components for displaying search results, formatting response text with hyperlinks to citations, and rendering search interfaces\n- **ui/full_graph.py**: Full graph visualization interface using Altair charts for entities and communities data\n- **ui/sidebar.py**: Sidebar UI components for managing search modes (local, drift, global, basic RAG) and dataset operations\n- **knowledge_loader/model.py**: Main interface for retrieving various data components from the knowledge graph and assembling KnowledgeModel objects\n- **knowledge_loader/data_sources/blob_source.py**: BlobDatasource class for reading data and settings from Azure Blob Storage\n- **knowledge_loader/data_sources/local_source.py**: LocalDatasource class for reading data files and configuration files from local directories\n- **ui/report_list.py**: UI component for displaying and selecting community reports\n- **ui/report_details.py**: UI components for displaying detailed report information including metadata, content, and entity relationships\n- **ui/questions_list.py**: UI component for displaying and selecting questions in the search application\n- **state/session_variables.py**: SessionVariables class for managing session state including dataset, question, and search flags\n- **state/session_variable.py**: SessionVariable class for managing session state variables with automatic naming and prefix support\n- **state/query_variable.py**: QueryVariable class for synchronizing URL query parameters with Streamlit session state\n- **data_config.py**: Configuration management for application data sources and settings\n\n### Main entry points\n- **main()** (home_page.py): Primary application entry point that initializes the Streamlit interface\n- **load_knowledge_model()** (app_logic.py): Loads knowledge models and datasets for search operations\n- **create_datasource()** (knowledge_loader/data_sources/loader.py): Creates datasources for reading from local or blob storage\n- **load_model()** (knowledge_loader/model.py): Assembles all graph data into a KnowledgeModel object\n- **SessionVariables** (state/session_variables.py): Centralized interface for accessing and managing session state variables\n- **create_side_bar()** (ui/sidebar.py): Creates the main sidebar UI with search mode controls and dataset operations\n\n### Dependencies and Configuration\nThe application requires Streamlit for the web interface and supports data loading from both local file systems and Azure Blob Storage. Configuration is managed through session state variables and query parameters that synchronize with URL parameters.\n\n### Example Usage\nTo run the application, execute the main entry point which initializes the Streamlit interface. Users can then select datasets, choose search methods (basic RAG, local search, global search, drift search), and interactively explore GraphRAG outputs through visualizations and detailed reports.\n\n## Files in this Module\n\n- [`unified-search-app/app/app_logic.py`](../files/unified-search-app-app-app-logic)\n- [`unified-search-app/app/home_page.py`](../files/unified-search-app-app-home-page)\n- [`unified-search-app/app/knowledge_loader/data_prep.py`](../files/unified-search-app-app-knowledge-loader-data-prep)\n- [`unified-search-app/app/knowledge_loader/data_sources/loader.py`](../files/unified-search-app-app-knowledge-loader-data-sources-loader)\n- [`unified-search-app/app/rag/__init__.py`](../files/unified-search-app-app-rag-init)\n- [`unified-search-app/app/ui/search.py`](../files/unified-search-app-app-ui-search)\n- [`unified-search-app/app/ui/full_graph.py`](../files/unified-search-app-app-ui-full-graph)\n- [`unified-search-app/app/ui/sidebar.py`](../files/unified-search-app-app-ui-sidebar)\n- [`unified-search-app/app/knowledge_loader/model.py`](../files/unified-search-app-app-knowledge-loader-model)\n- [`unified-search-app/app/knowledge_loader/data_sources/blob_source.py`](../files/unified-search-app-app-knowledge-loader-data-sources-blob-source)\n- [`unified-search-app/app/knowledge_loader/data_sources/local_source.py`](../files/unified-search-app-app-knowledge-loader-data-sources-local-source)\n- [`unified-search-app/app/ui/report_list.py`](../files/unified-search-app-app-ui-report-list)\n- [`unified-search-app/app/ui/report_details.py`](../files/unified-search-app-app-ui-report-details)\n- [`unified-search-app/app/ui/questions_list.py`](../files/unified-search-app-app-ui-questions-list)\n- [`unified-search-app/app/state/session_variables.py`](../files/unified-search-app-app-state-session-variables)\n- [`unified-search-app/app/state/session_variable.py`](../files/unified-search-app-app-state-session-variable)\n- [`unified-search-app/app/state/query_variable.py`](../files/unified-search-app-app-state-query-variable)\n- [`unified-search-app/app/data_config.py`](../files/unified-search-app-app-data-config)"
        }
      ]
    }
  ]
}